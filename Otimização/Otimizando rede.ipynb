{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final Redes Neurais: Propriedades Mecânicas de Materiais\n",
    "\n",
    "#### Trio: csv_Computeiros_sinápticos_virtuais \n",
    "\n",
    "#### Integrantes: Diogo Pereira de Lima Carvalho, José David Sales e Mayllon Emmanoel Pequeno\n",
    "\n",
    "<p style=\"text-align: justify;\"> O notebook em questão consiste no processo de otimização de hiperparâmetros da rede neural MLP. Para isso, utilizou-se o <code>optuna</code>, baseando-se em um notebook do professor Daniel Roberto Cassar [1]. Para essa otimização, considerou-se variar o número de camadas ocultas, o número de neurônios por camada oculta e se os neurôneos de cada camada apresentam ou não viés.\n",
    "\n",
    "<p style=\"text-align: justify;\"> Abaixo, foram importadas as bibliotecas necessárias e determinadas as constantes utilizadas neste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from objetos_otimizacao_rede_neural import *\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from optuna import create_study, Trial\n",
    "import os\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 0\n",
    "NUM_TENTATIVAS_OTIMIZACAO = 500\n",
    "NUM_EPOCAS = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> Abaixo, foi utilizado a instância <code>logger</code> para guardar informações importantes sobre as métricas de desempenho do modelo que será treinado. Um <code>treinador</code> também é criado que será responsável pelos ciclos de treinamamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(save_dir=os.getcwd(), version=1, name=\"lightning_logs/\")\n",
    "treinador = L.Trainer(logger=False,enable_checkpointing=True,max_epochs=NUM_EPOCAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> Abaixo, a função <code>build_model</code> cria uma instância do modelo, em que há 5 dados de entrada (5 atributos) e 1 dado de saída, já que se possui apenas um <i>target</i> numérico. Nisso, em cada tentativa, pode-se variar o número de camadas (entre 2 e 5), o número de neurônios por camada (de 2 a 15) e se haverá ou não viés para neurônios de cada camada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(trial):\n",
    "    num_dados_de_entrada = 5\n",
    "    num_dados_de_saida = 1\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5) \n",
    "    neuronios_camadas = []\n",
    "    vieses = []\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        neuronios =  trial.suggest_int(f\"c{i}\", 2, 15)\n",
    "        bia = trial.suggest_categorical(f\"bias{i}\", [False, True])\n",
    "        neuronios_camadas.append(neuronios)\n",
    "        vieses.append(bia)\n",
    "        \n",
    "    bia = trial.suggest_categorical(f\"bia out\", [False, True])\n",
    "    vieses.append(bia)\n",
    "    \n",
    "    minha_mlp = MLP(\n",
    "        num_dados_de_entrada, list(neuronios_camadas), list(vieses), num_dados_de_saida\n",
    "    )\n",
    "    \n",
    "    return minha_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> Abaixo, é defido a função <code>objective</code>, responsável por computar a métrica RMSE para a MLP com uma validação cruzada realizada a partir da iteração abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    k = []\n",
    "    for i in range(int(1/TAMANHO_TESTE)):\n",
    "        print(i)\n",
    "        dm = DataModule(TAMANHO_TESTE, SEMENTE_ALEATORIA, i)\n",
    "        minha_mlp = build_model(trial)\n",
    "        treinador.fit(minha_mlp, dm)\n",
    "\n",
    "        minha_mlp.eval()\n",
    "        dm.setup(\"test\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X_true = dm.X_teste\n",
    "\n",
    "            y_true = dm.y_teste\n",
    "            y_true = dm.y_scaler.inverse_transform(y_true)\n",
    "\n",
    "            y_pred = minha_mlp(X_true)\n",
    "            y_pred = dm.y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "            RMSE = root_mean_squared_error(y_true, y_pred)\n",
    "        \n",
    "        k.append(RMSE)\n",
    "\n",
    "    rmse_medio = (sum(np.array(k)**2)/int(1/TAMANHO_TESTE))**.5\n",
    "    return rmse_medio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> Por fim, criou-se a instância de estudo de <code>create_study</code>, sendo utilizado para resolver um problema de minimização. A partir disso, realia-se um certo número de tentaticas de modelos conforme o número determinado na constante <code>NUM_TENTATIVAS_OTIMIZACAO</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "study = create_study(direction='minimize')\n",
    "parametros_totais = []\n",
    "\n",
    "for _ in range(NUM_TENTATIVAS_OTIMIZACAO):\n",
    "    study.optimize(objective, n_trials=1)\n",
    "    clear_output()\n",
    "    study.trials_dataframe().to_excel('triagem.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> A partir das tentativas de modelos, o considerado melhor modelo, o que possui um menor valor de <i>RMSE</i>, teve seus hiperparâmetros exibidos salvo no <code>melhor_trial</code>. No caso abaixo, da forma que está salvo no github, perceba que o melhor modelo possui três camadas ocultas com pesos variados, das quais apenas a primeira camada não possui viés e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 244\n",
      "Parâmetros do melhor trial: {'n_layers': 3, 'c0': 7, 'bias0': False, 'c1': 11, 'bias1': True, 'c2': 12, 'bias2': True, 'bia out': False}\n",
      "Valor do RMSE do melhor trial: 378.64423586770613 MPa\n"
     ]
    }
   ],
   "source": [
    "melhor_trial = study.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial: {melhor_trial.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {melhor_trial.params}\")\n",
    "print(f\"Valor do RMSE do melhor trial: {melhor_trial.value} MPa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> A partir dos hiperparâmetros, criou-se um modelo de rede neural com esses hiperparâmetros, sendo dessa vez testada com o que foi chamado de <code>test_premium</code>, um conjunto de 10% dos exemplos dataset que não foi exposto ao modelo durante o treinamento e a otimização de hiperparâmetro. Testou-se nesse conjunto para averiguar o valor da métrica <i>RMSE</i> que seja mais confiável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197.1079938383723\n"
     ]
    }
   ],
   "source": [
    "# O número de dados de entrada (número de atributos) e o número de dados de saída são sempre os mesmos\n",
    "num_dados_de_entrada = 5 \n",
    "num_dados_de_saida = 1\n",
    "\n",
    "# abaixo, foi salvo \n",
    "layers_number = int((len(melhor_trial.params) - 1) / 2) \n",
    "\n",
    "neuronios_camadas = []\n",
    "vieses = []\n",
    "\n",
    "for i in range(layers_number):\n",
    "    neuronios_camadas.append(melhor_trial.params[f'c{i}'])\n",
    "    vieses.append(melhor_trial.params[f'bias{i}'])\n",
    "vieses.append(melhor_trial.params[f'bia out'])\n",
    "\n",
    "# Criação do modelo com os hiperparâmetros utilizados\n",
    "minha_mlp = MLP(\n",
    "    num_dados_de_entrada, list(neuronios_camadas), list(vieses), num_dados_de_saida\n",
    ")\n",
    "\n",
    "dm = DataModule(TAMANHO_TESTE, SEMENTE_ALEATORIA, 1)\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=os.getcwd(), version=1, name=\"lightning_logs/\")\n",
    "treinador = L.Trainer(logger=False, enable_checkpointing=True, max_epochs=NUM_EPOCAS)\n",
    "\n",
    "treinador.fit(minha_mlp, dm)dm.setup(\"test\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_true = dm.X_teste_premium\n",
    "\n",
    "    y_true = dm.y_teste_premium\n",
    "    y_true = dm.y_scaler.inverse_transform(y_true)\n",
    "\n",
    "    y_pred = minha_mlp(X_true)\n",
    "    y_pred = dm.y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "    RMSE = root_mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> Acima, note que o modelo obteve um RMSE de 182.528 MPa, ainda menor que o resgistrado durante a otimização, o que é no mínimo interessante. Portanto, a partir da otimização de hiperparâmetros com 1000 tentativa variando o número de camadas ocultas e de neurônios por camada oculta, além da presença ou não de viés de neurônios a cada camada, foi possível obter um resultado ainda melhor, com um menor valor de RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências:\n",
    "\n",
    "[1] Cassar, D. R. 11 - Otimização de hiperparâmetros. Notebook Jupyter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ilumpy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8529d5d23f5cbf0c063605dab2c59e7e62347018e6f532e027d68294076af1e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
