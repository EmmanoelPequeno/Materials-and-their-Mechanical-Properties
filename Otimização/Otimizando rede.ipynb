{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final Redes Neurais: Propriedades Mecânicas de Materiais\n",
    "\n",
    "#### Trio: csv_Computeiros_sinápticos_virtuais \n",
    "\n",
    "#### Integrantes: Diogo Pereira de Lima Carvalho, José David Sales e Mayllon Emmanoel Pequeno\n",
    "\n",
    "<p style=\"text-align: justify;\"> O notebook em questão consiste no processo de otimização de hiperparâmetros da rede neural MLP. Para isso, utilizou-se o <code>optuna</code>, baseando-se em um notebook do professor Daniel Roberto Cassar [1]. Para essa otimização, \n",
    "\n",
    "<p style=\"text-align: justify;\"> Abaixo, foram importadas as bibliotecas necessárias e determinadas as constantes utilizadas neste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from objetos_otimizacao_rede_neural import *\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from optuna import create_study, Trial\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 0\n",
    "NUM_TENTATIVAS_OTIMIZACAO = 500\n",
    "NUM_EPOCAS = 15\n",
    "NUM_EPOCAS_FINAL = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> Abaixo, foi utilizado a instância <code>logger</code> para guardar informações importantes sobre as métricas de desempenho do modelo que será treinado. Um <code>treinador</code> também é criado que será responsável pelos ciclos de treinamamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(save_dir=os.getcwd(), version=1, name=\"lightning_logs/\")\n",
    "treinador = L.Trainer(logger=False,enable_checkpointing=True,max_epochs=NUM_EPOCAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> Abaixo, a função <code>build_model</code> cria uma instância do modelo, em que há 5 dados de entrada (5 atributos) e 1 dado de saída, já que se possui apenas um <i>target</i> numérico. Nisso, em cada tentativa, pode-se variar o número de camadas (entre 2 e 5), o número de neurônios por camada (de 2 a 15) e se haverá ou não viés para neurônios de cada camada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(trial):\n",
    "    num_dados_de_entrada = 5\n",
    "    num_dados_de_saida = 1\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n",
    "    neuronios_camadas = []\n",
    "    vieses = []\n",
    "    for i in range(n_layers):\n",
    "        neuronios =  trial.suggest_int(f\"c{i}\", 2, 15)\n",
    "        bia = trial.suggest_categorical(f\"bias{i}\", [False, True])\n",
    "        neuronios_camadas.append(neuronios)\n",
    "        vieses.append(bia)\n",
    "        \n",
    "    bia = trial.suggest_categorical(f\"bia out\", [False, True])\n",
    "    vieses.append(bia)\n",
    "    \n",
    "    minha_mlp = MLP(\n",
    "        num_dados_de_entrada, list(neuronios_camadas), list(vieses), num_dados_de_saida\n",
    "    )\n",
    "    \n",
    "    return minha_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> Abaixo, é defido a função <code>objective</code>, responsável por computar a métrica RMSE para a MLP com uma validação cruzada realizada a partir da iteração abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "minha_mlp = MLP(5,[3,4,5],[True,False,False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (camadas): Sequential(\n",
       "    (linear0): Linear(in_features=5, out_features=3, bias=True)\n",
       "    (relu0): ReLU()\n",
       "    (linear1): Linear(in_features=3, out_features=4, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (linear2): Linear(in_features=4, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minha_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    k = []\n",
    "    for i in range(int(1/TAMANHO_TESTE)):\n",
    "        print(i)\n",
    "        dm = DataModule(TAMANHO_TESTE, SEMENTE_ALEATORIA, i)\n",
    "        minha_mlp = build_model(trial)\n",
    "        treinador.fit(minha_mlp, dm)\n",
    "\n",
    "        minha_mlp.eval()\n",
    "        dm.setup(\"test\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X_true = dm.X_teste\n",
    "\n",
    "            y_true = dm.y_teste\n",
    "            y_true = dm.y_scaler.inverse_transform(y_true)\n",
    "\n",
    "            y_pred = minha_mlp(X_true)\n",
    "            y_pred = dm.y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "            RMSE = root_mean_squared_error(y_true, y_pred)\n",
    "        \n",
    "        k.append(RMSE)\n",
    "\n",
    "    rmse_medio = (sum(np.array(k)**2)/int(1/TAMANHO_TESTE))**.5\n",
    "    return rmse_medio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\"> Por fim, criou-se a instância de estudo de <code>create_study</code>, sendo utilizado para resolver um problema de minimização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-06 22:37:00,802] A new study created in memory with name: no-name-af25526a-4322-4a2c-8ee3-324a988827e6\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | camadas | Sequential | 218   \n",
      "---------------------------------------\n",
      "218       Trainable params\n",
      "0         Non-trainable params\n",
      "218       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | camadas | Sequential | 218   \n",
      "---------------------------------------\n",
      "218       Trainable params\n",
      "0         Non-trainable params\n",
      "218       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "study = create_study(direction='minimize')\n",
    "parametros_totais = []\n",
    "\n",
    "for _ in range(NUM_TENTATIVAS_OTIMIZACAO):\n",
    "\n",
    "    study.optimize(objective, n_trials=1)\n",
    "    study.trials_dataframe().to_excel('triagem.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial: 339\n",
      "Parâmetros do melhor trial: {'n_layers': 5, 'c0': 8, 'bias0': True, 'c1': 8, 'bias1': True, 'c2': 8, 'bias2': False, 'c3': 7, 'bias3': False, 'c4': 11, 'bias4': False}\n"
     ]
    }
   ],
   "source": [
    "melhor_trial = study.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial: {melhor_trial.number}\")\n",
    "print(f\"Parâmetros do melhor trial: {melhor_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [8, 8, 8, 7, 11] [True, True, False, False, False] 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\venv\\ilumpy\\lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:69: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "c:\\venv\\ilumpy\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory c:\\Users\\diogo23039\\OneDrive - ILUM ESCOLA DE CIÊNCIA\\3º Semestre\\Redes Neurais e Algoritmos Genéticos\\Trabalho Final de Redes Neurais\\Materials-and-their-Mechanical-Properties\\Otimização\\checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | camadas | Sequential | 262   \n",
      "---------------------------------------\n",
      "262       Trainable params\n",
      "0         Non-trainable params\n",
      "262       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885863f37add4720a51a1837f426804e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268.25710916867126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venv\\ilumpy\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_dados_de_entrada = 5\n",
    "num_dados_de_saida = 1\n",
    "\n",
    "\n",
    "layers_number = int((len(melhor_trial.params) - 1) / 2)\n",
    "\n",
    "neuronios_camadas = []\n",
    "vieses = []\n",
    "\n",
    "for i in range(layers_number):\n",
    "    neuronios_camadas.append(melhor_trial.params[f'c{i}'])\n",
    "    vieses.append(melhor_trial.params[f'bias{i}'])\n",
    "\n",
    "print(num_dados_de_entrada, list(neuronios_camadas), list(vieses), num_dados_de_saida)\n",
    "\n",
    "minha_mlp = MLP(\n",
    "    num_dados_de_entrada, list(neuronios_camadas), list(vieses), num_dados_de_saida\n",
    ")\n",
    "\n",
    "dm = DataModule(TAMANHO_TESTE, SEMENTE_ALEATORIA, 1)\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=os.getcwd(), version=1, name=\"lightning_logs/\")\n",
    "treinador = L.Trainer(logger=False, enable_checkpointing=True, max_epochs=NUM_EPOCAS_FINAL)\n",
    "\n",
    "treinador.fit(minha_mlp, dm)\n",
    "\n",
    "dm.setup(\"test\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_true = dm.X_teste_premium\n",
    "\n",
    "    y_true = dm.y_teste_premium\n",
    "    y_true = dm.y_scaler.inverse_transform(y_true)\n",
    "\n",
    "    y_pred = minha_mlp(X_true)\n",
    "    y_pred = dm.y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "    RMSE = mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "    print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 0\n",
    "NUM_TENTATIVAS_OTIMIZACAO = 500\n",
    "NUM_EPOCAS = 15\n",
    "NUM_EPOCAS_FINAL = 30\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=os.getcwd(), version=1, name=\"lightning_logs/\")\n",
    "treinador = L.Trainer(logger=False,enable_checkpointing=True,max_epochs=NUM_EPOCAS)\n",
    "\n",
    "\n",
    "def build_model(trial):\n",
    "    num_dados_de_entrada = 5\n",
    "    num_dados_de_saida = 1\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n",
    "    neuronios_camadas = []\n",
    "    vieses = []\n",
    "    for i in range(n_layers):\n",
    "        neuronios =  trial.suggest_int(f\"c{i}\", 2, 15)\n",
    "        bia = trial.suggest_categorical(f\"bias{i}\", [False, True])\n",
    "        neuronios_camadas.append(neuronios)\n",
    "        vieses.append(bia)\n",
    "    \n",
    "    minha_mlp = MLP(\n",
    "        num_dados_de_entrada, list(neuronios_camadas), list(vieses), num_dados_de_saida\n",
    "    )\n",
    "    \n",
    "    return minha_mlp\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    k = []\n",
    "    for i in range(int(1/TAMANHO_TESTE)):\n",
    "        print(i)\n",
    "        dm = DataModule(TAMANHO_TESTE, SEMENTE_ALEATORIA, i)\n",
    "        minha_mlp = build_model(trial)\n",
    "        treinador.fit(minha_mlp, dm)\n",
    "\n",
    "        minha_mlp.eval()\n",
    "        dm.setup(\"test\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X_true = dm.X_teste\n",
    "\n",
    "            y_true = dm.y_teste\n",
    "            y_true = dm.y_scaler.inverse_transform(y_true)\n",
    "\n",
    "            y_pred = minha_mlp(X_true)\n",
    "            y_pred = dm.y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "            RMSE = root_mean_squared_error(y_true, y_pred)\n",
    "        \n",
    "        k.append(RMSE)\n",
    "\n",
    "    rmse_medio = (sum(np.array(k)**2)/int(1/TAMANHO_TESTE))**.5\n",
    "    return rmse_medio\n",
    "\n",
    "study = create_study(direction='minimize')\n",
    "parametros_totais = []\n",
    "\n",
    "for _ in range(NUM_TENTATIVAS_OTIMIZACAO):\n",
    "\n",
    "    study.optimize(objective, n_trials=1)\n",
    "    study.trials_dataframe().to_excel('triagem.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
